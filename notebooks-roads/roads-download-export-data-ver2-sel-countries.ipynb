{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the roads data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How many m/km of roads were mapped with RapID in selected region?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data for every specified region"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing variables\n",
    "desired_countries = [\"US1\", \"NGA\", \"DEU\", \"CZE\", \"VNM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geojson-africa-states',\n",
       " 'geojson-africa-test-states',\n",
       " 'geojson-asia-states',\n",
       " 'geojson-continent-states',\n",
       " 'geojson-europe-states',\n",
       " 'geojson-northamerica-states',\n",
       " 'geojson-world-states-ohsome',\n",
       " 'geojson-world-states']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_geojson_names():\n",
    "\n",
    "    home_dir = os.getcwd()\n",
    "    geojson_dir = os.path.join(home_dir, f\"geojson-regions\", \"\")\n",
    "\n",
    "    # Construct the file pattern\n",
    "    file_pattern = os.path.join(geojson_dir, '*.geojson')\n",
    "    # print(file_pattern)\n",
    "\n",
    "    # Use glob to get the list of file names matching the pattern\n",
    "    file_names = glob.glob(file_pattern)\n",
    "    # print(file_names)\n",
    "\n",
    "    # Extract the base names of the files without the extension\n",
    "    names = [os.path.splitext(os.path.basename(file_name))[0]\n",
    "            for file_name in file_names]\n",
    "    # print(names)\n",
    "    # Print the names\n",
    "\n",
    "    return names\n",
    "    \n",
    "\n",
    "geojson_names = get_geojson_names()\n",
    "geojson_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'geojson-africa-states',\n",
       " 1: 'geojson-africa-test-states',\n",
       " 2: 'geojson-asia-states',\n",
       " 3: 'geojson-continent-states',\n",
       " 4: 'geojson-europe-states',\n",
       " 5: 'geojson-northamerica-states',\n",
       " 6: 'geojson-world-states-ohsome',\n",
       " 7: 'geojson-world-states'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geojson_dic = {k: v for k, v in enumerate(geojson_names)}\n",
    "geojson_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary is not empty\n"
     ]
    }
   ],
   "source": [
    "if bool(geojson_dic):\n",
    "    print(\"Dictionary is not empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the user input\n",
    "\n",
    "while True:\n",
    "    if bool(geojson_dic):\n",
    "        try:\n",
    "            user_d_spec = int(input(f\"Which data do you want to download?\\\n",
    "                                Enter {geojson_dic}\"\n",
    "                                    ))\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "            continue\n",
    "        if user_d_spec not in range(len(geojson_dic)):\n",
    "            print(f\"Please enter {len(geojson_dic.keys())}\")\n",
    "            continue\n",
    "        break\n",
    "    else:\n",
    "        print(\"Geojson_dic is empty, restart the kernel, please.\")\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_d_format = int(input(\"Which data format do you want to export?\\\n",
    "                            Enter 0 for json format\\\n",
    "                            or 1 for geojson format\"\n",
    "                                ))\n",
    "    except ValueError:\n",
    "        print(\"Please enter a number.\")\n",
    "        continue\n",
    "    if user_d_format not in range(0, 2):\n",
    "        print(\"Please enter 0 or 1.\")\n",
    "        continue\n",
    "    break\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_sel_countries = input(\"Do you want to download data for desired countries defined in a list in the code?\\\n",
    "                                        Enter y for yes or n for no\"\n",
    "                                   )\n",
    "    except ValueError as e:\n",
    "        print(\"Error: \", e)\n",
    "        continue\n",
    "    if user_sel_countries != \"y\" and user_sel_countries != \"n\":\n",
    "        print(\"Please enter y or n.\")\n",
    "        continue\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read geojson data\n",
    "\n",
    "# os.chdir('..')\n",
    "# home_wd = os.getcwd()\n",
    "# downloaded_data_geojson_dir = os.path.join(home_wd, \"downloaded-data-geojson\", \"\")\n",
    "\n",
    "with open(f\"geojson-regions\\\\{geojson_dic[user_d_spec]}.geojson\", \"r\") as file:\n",
    "    bpolys = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the functions\n",
    "\n",
    "def convert_geojson_structure(original_dict):\n",
    "    \"\"\"Convert the GeoJSON structure to the structure required by the API.\"\"\"\n",
    "\n",
    "    new_dict = {}\n",
    "    new_dict[\"type\"] = \"FeatureCollection\"\n",
    "    new_dict[\"features\"] = []\n",
    "\n",
    "    feature_dict = {}\n",
    "    feature_dict[\"type\"] = \"Feature\"\n",
    "    feature_dict[\"geometry\"] = {}\n",
    "    feature_dict[\"geometry\"][\"type\"] = \"MultiPolygon\"\n",
    "\n",
    "    new_dict[\"features\"].append(feature_dict)\n",
    "\n",
    "    feature_dict[\"geometry\"][\"coordinates\"] = original_dict[\"geometry\"][\"coordinates\"]\n",
    "    # feature_dict[\"geometry\"][\"type\"] = \"MultiPolygon\"\n",
    "    feature_dict[\"properties\"] = original_dict[\"properties\"]\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "# append desired properties\n",
    "def append_properties(result, desired_geojson_structure):\n",
    "    \"\"\"Add the desired properties to the result of the API call.\"\"\"\n",
    "\n",
    "    desired_properties = [\"ADM0_ISO\", \"SOVEREIGNT\",\n",
    "                          \"TYPE\", \"ADMIN\", \"GEOUNIT\", \"NAME\", \"NE_ID\",\n",
    "                          \"POP_EST\", \"POP_RANK\", \"POP_YEAR\", \"GDP_MD\", \"GDP_YEAR\",\n",
    "                          \"ECONOMY\", \"INCOME_GRP\", \"CONTINENT\", \"REGION_UN\", \"SUBREGION\", \"REGION_WB\"]\n",
    "\n",
    "    for region in result:\n",
    "        region[\"groupByObject\"][0] = desired_geojson_structure[\"features\"][0][\"properties\"][\"NAME_EN\"]\n",
    "\n",
    "        for property in desired_properties:\n",
    "            region[\"groupByObject\"].append(desired_geojson_structure[\"features\"][0][\"properties\"][property])\n",
    "\n",
    "    return result\n",
    "\n",
    "def data_gen(feature):\n",
    "    \"\"\" Get data from the API.\"\"\"\n",
    "\n",
    "    desired_geojson_structure = convert_geojson_structure(feature)\n",
    "\n",
    "    parameters = {\n",
    "        \"bpolys\": json.dumps(desired_geojson_structure),  # pass GeoJSON as string.\n",
    "        \"filter\": \"type: way and (highway in (motorway,\\\n",
    "                                              motorway_link, trunk, trunk_link,\\\n",
    "                                              primary, primary_link, secondary,\\\n",
    "                                              secondary_link, tertiary,\\\n",
    "                                              tertiary_link, unclassified,\\\n",
    "                                              residential, living_street, pedestrian, footway, cycleway, track, path)\\\n",
    "                                  or (highway=service and service=alley))\",\n",
    "        \"groupByKey\": \"source\",\n",
    "        \"groupByValues\": \"maxar\",\n",
    "        \"format\": \"json\",\n",
    "        \"time\": \"2023-06-30\",  # \"2018-01-01/2023-06-30/P1Y\" 2023-06-30\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    }\n",
    "\n",
    "    for value in parameters.values():\n",
    "        assert value != \"\", \"Please provide values for the parameters\"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.post(url, data=parameters, headers=headers)\n",
    "            response.raise_for_status()  # Raise an Exception if HTTP Status Code is not 200\n",
    "\n",
    "            # print(\"Response:\")\n",
    "            # print(desired_geojson_structure[\"features\"][0][\"properties\"][\"NAME_EN\"])\n",
    "            # print(json.dumps(response.json(), indent=4))  # Pretty print response\n",
    "\n",
    "            result = response.json()[\"groupByResult\"]\n",
    "\n",
    "            # for region in result:\n",
    "            #     region[\"groupByObject\"][0] = desired_geojson_structure[\"features\"][0][\"properties\"][\"NAME_EN\"]\n",
    "\n",
    "            fin_res = append_properties(result, desired_geojson_structure)\n",
    "\n",
    "            # print(json.dumps(fin_res, indent=4))  # Pretty print response\n",
    "            return fin_res\n",
    "\n",
    "        \n",
    "        except requests.exceptions.RequestException:\n",
    "            # Wi-Fi connection error occurred, wait for connection to be restored\n",
    "            print(\"Waiting for Wi-Fi connection to be restored...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds\n",
    "            continue  # Continue to the next iteration of the loop\n",
    "\n",
    "# longer version of the function\n",
    "# def connect_feat_data(feature, data):\n",
    "\n",
    "#     # Find the relevant value in data\n",
    "#     rem_value_to_add = None\n",
    "#     for elem in data:\n",
    "#         if elem['groupByObject'][1] == 'remainder':\n",
    "#             for result in elem['result']:\n",
    "#                 if result['timestamp'] == '2023-01-01T00:00:00Z':\n",
    "#                     rem_value_to_add = result['value']\n",
    "#                     break\n",
    "#             break\n",
    "\n",
    "\n",
    "#     ai_value_to_add = None\n",
    "#     for elem in data:\n",
    "#         if elem['groupByObject'][1] == 'source=maxar':\n",
    "#             for result in elem['result']:\n",
    "#                 if result['timestamp'] == '2023-01-01T00:00:00Z':\n",
    "#                     ai_value_to_add = result['value']\n",
    "#                     break\n",
    "#             break\n",
    "#     # return value_to_add\n",
    "\n",
    "\n",
    "#     roads_total = None\n",
    "#     roads_total = rem_value_to_add + ai_value_to_add\n",
    "\n",
    "#     # Calculate the AI percentage\n",
    "#     ai_percentage = None\n",
    "#     ai_percentage = (ai_value_to_add / (ai_value_to_add + rem_value_to_add)) * 100\n",
    "    \n",
    "#     # Add the value to the properties of feature\n",
    "#     if rem_value_to_add is not None:\n",
    "#         feature['properties']['mm_roads_2023'] = rem_value_to_add\n",
    "\n",
    "#     if ai_value_to_add is not None:\n",
    "#         feature['properties']['ai_roads_2023'] = ai_value_to_add\n",
    "\n",
    "#     if roads_total is not None:\n",
    "#         feature['properties']['roads_total'] = roads_total\n",
    "\n",
    "#     if ai_percentage is not None:\n",
    "#         feature['properties']['ai_percentage'] = ai_percentage\n",
    "\n",
    "#     return feature\n",
    "\n",
    "\n",
    "def connect_feat_data(feature, data):\n",
    "    \"\"\"Connects the data to the feature of the GeoJSON file\"\"\"\n",
    "\n",
    "    rem_value_to_add = None\n",
    "    ai_value_to_add = None\n",
    "\n",
    "    for elem in data:\n",
    "        if elem['groupByObject'][1] == 'remainder':\n",
    "            rem_value_to_add = find_value(elem, '2023-06-30T00:00:00Z')\n",
    "        elif elem['groupByObject'][1] == 'source=maxar':\n",
    "            ai_value_to_add = find_value(elem, '2023-06-30T00:00:00Z')\n",
    "\n",
    "    roads_total = rem_value_to_add + ai_value_to_add\\\n",
    "        if rem_value_to_add is not None and ai_value_to_add is not None else None\n",
    "    ai_percentage = (ai_value_to_add / (ai_value_to_add + rem_value_to_add)) * 100\\\n",
    "        if rem_value_to_add is not None and ai_value_to_add is not None else None\n",
    "\n",
    "    if rem_value_to_add is not None:\n",
    "        feature['properties']['mm_roads_2023'] = rem_value_to_add\n",
    "\n",
    "    if ai_value_to_add is not None:\n",
    "        feature['properties']['ai_roads_2023'] = ai_value_to_add\n",
    "\n",
    "    if roads_total is not None:\n",
    "        feature['properties']['roads_total'] = roads_total\n",
    "\n",
    "    if ai_percentage is not None:\n",
    "        feature['properties']['ai_percentage'] = ai_percentage\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "def sel_countries_from_geojson(bpolys, desired_countries):\n",
    "    \"\"\"Get the celected countries from the geojson file.\"\"\"\n",
    "\n",
    "    sel_countries = {\"features\": []}\n",
    "\n",
    "    # desired_countries = [\"US1\", \"NGA\", \"DEU\", \"CZE\", \"VNM\"]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            for i in range(len(bpolys[\"features\"])):\n",
    "                if bpolys[\"features\"][i][\"properties\"][\"ADM0_A3\"] in desired_countries:\n",
    "                    sel_country = bpolys[\"features\"][i]\n",
    "                    sel_countries[\"features\"].append(sel_country)\n",
    "                    print(i, bpolys[\"features\"][i][\"properties\"][\"ADM0_A3\"])\n",
    "                    desired_countries.remove(\n",
    "                        bpolys[\"features\"][i][\"properties\"][\"ADM0_A3\"])\n",
    "        except KeyError:\n",
    "            print(\"You are trying to access a key that does not exist. Please try to use a geojson format in different structure.\")\n",
    "            break\n",
    "        break\n",
    "\n",
    "    print(f\"Countries not in downloaded data: {desired_countries}\")\n",
    "\n",
    "    return sel_countries\n",
    "\n",
    "\n",
    "def find_value(elem, timestamp):\n",
    "    for result in elem['result']:\n",
    "        if result['timestamp'] == timestamp:\n",
    "            return result['value']\n",
    "    print(f\"Value for {timestamp} not found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def return_json_data(bpolys=bpolys):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    features = bpolys[\"features\"]\n",
    "\n",
    "    # data = [data_gen(feature) for feature in bpolys[\"features\"] if feature[\"properties\"][\"ADM0_ISO\"] in desired_countries]\n",
    "    # for country in desired_countries:\n",
    "    for i, feature in tqdm(enumerate(features), total=len(features)):\n",
    "        # if feature[\"properties\"][\"ADM0_ISO\"] in desired_countries:\n",
    "        obtained_data = data_gen(feature)\n",
    "\n",
    "        data.append(obtained_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def return_geojson_data(bpolys=bpolys):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    features = bpolys[\"features\"]\n",
    "    for i, feature in tqdm(enumerate(features), total=len(features)):\n",
    "\n",
    "        obtained_data = data_gen(feature)\n",
    "        # print(data)\n",
    "        feat_with_data = connect_feat_data(feature, obtained_data)\n",
    "        # print(feat_with_data)\n",
    "        # print(feature)\n",
    "        data.append(feat_with_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "# export the data\n",
    "def export_data_as_json(name, data):\n",
    "    with open(f\"downloaded-data-json\\\\roads_{name}.json\", \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "\n",
    "# export_data_as_json(data_dic[user_d_spec], return_json_data)\n",
    "\n",
    "\n",
    "def export_data_as_geojson(name, data):\n",
    "\n",
    "    # Define the filename for the GeoJSON file\n",
    "    filename = f'roads_{name}.geojson'\n",
    "\n",
    "    # Create a FeatureCollection from the structure\n",
    "    feature_collection = {\n",
    "        'type': 'FeatureCollection',\n",
    "        'features': data\n",
    "    }\n",
    "\n",
    "    # Write the FeatureCollection to a GeoJSON file\n",
    "    with open(f\"downloaded-data-geojson\\\\{filename}\", 'w') as file:\n",
    "        json.dump(feature_collection, file, indent=4)\n",
    "\n",
    "\n",
    "# export_data_as_geojson(data_dic[user_d_spec], return_geojson_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the URL\n",
    "\n",
    "base_url = \"https://api.ohsome.org/v1\"\n",
    "endpoint = \"/elements/length/groupBy/boundary/groupBy/tag\"\n",
    "url = base_url + endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_geojson_structure(bpolys[\"features\"][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [35:02<00:00, 10.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "json_data = []\n",
    "geojson_data = []\n",
    "\n",
    "fin_file_name = input(\"Enter the name of the file to export the data: \")\n",
    "\n",
    "if user_d_format == 0:  # 0 for json format\n",
    "    if user_sel_countries == \"y\":  # y just for selected countries\n",
    "        sel_countries = sel_countries_from_geojson(bpolys, desired_countries)\n",
    "        obtained_json_data = return_json_data(sel_countries)\n",
    "        json_data.extend(obtained_json_data)\n",
    "        export_data_as_json(fin_file_name, obtained_json_data)\n",
    "    else:\n",
    "        obtained_json_data = return_json_data()\n",
    "        json_data.extend(obtained_json_data)\n",
    "        export_data_as_json(fin_file_name, obtained_json_data)\n",
    "else:\n",
    "    if user_sel_countries == \"y\":  # y just for selected countries\n",
    "        sel_countries = sel_countries_from_geojson(bpolys, desired_countries)\n",
    "        obtained_geojson_data = return_geojson_data(sel_countries)\n",
    "        geojson_data.extend(obtained_geojson_data)\n",
    "        export_data_as_geojson(fin_file_name, obtained_geojson_data)\n",
    "    else:\n",
    "        obtained_geojson_data = return_geojson_data()\n",
    "        geojson_data.extend(obtained_geojson_data)\n",
    "        export_data_as_geojson(fin_file_name, obtained_geojson_data)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping the script.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milan\\general_py_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3386: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if user_d_format == 0:  # 0 for json format\n",
    "    with open(f\"downloaded-data-json\\\\roads_{geojson_dic[user_d_spec]}.json\", \"r\") as file:\n",
    "        dow_res = json.load(file)\n",
    "else:\n",
    "    print(\"Stopping the script.\")\n",
    "    raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_downloaded_data(dow_res):\n",
    "\n",
    "    new_dic = {\"state\": [], \"source\": [], \"timestamp\": [], \"value\": []}\n",
    "\n",
    "    flatten_data = [i for i in dow_res for i in i]\n",
    "    \n",
    "    for dic in flatten_data:\n",
    "        # print(dic)\n",
    "        state = dic[\"groupByObject\"][0]\n",
    "        source = dic[\"groupByObject\"][1]\n",
    "\n",
    "        for d in dic[\"result\"]:\n",
    "            timestamp = d[\"timestamp\"]\n",
    "            value = d[\"value\"]\n",
    "\n",
    "            # Append the corresponding state and source for each timestamp-value pair\n",
    "            new_dic[\"state\"].append(state)\n",
    "            new_dic[\"source\"].append(source)\n",
    "            new_dic[\"timestamp\"].append(timestamp)\n",
    "            new_dic[\"value\"].append(value)\n",
    "\n",
    "    return new_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>source</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>2.690817e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>2.805054e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>2.919187e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>3.031043e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>3.100596e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>3.176620e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>1.433720e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>2.068170e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>1.003840e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>1.495826e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Germany</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>2.079981e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Germany</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>2.113747e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Germany</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>2.144786e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Germany</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>2.187509e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Germany</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>2.224032e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Germany</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>2.253637e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Germany</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Germany</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Germany</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>3.597626e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Germany</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>3.688894e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Germany</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>3.302063e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Germany</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>3.324734e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>1.486511e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>1.749341e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>2.070022e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>4.444431e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>5.253196e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>5.307533e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>2.309823e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>5.231692e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>1.133991e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>1.133421e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>5.281016e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>6.699778e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>6.893288e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>7.173629e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>7.514205e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>7.774466e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>1.519000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>6.511065e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>4.281484e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>1.151075e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>1.065530e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>1.073248e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>1.081869e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>1.093930e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>1.106308e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>remainder</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>1.116729e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2019-01-01T00:00:00Z</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2020-01-01T00:00:00Z</td>\n",
       "      <td>7.345000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2021-01-01T00:00:00Z</td>\n",
       "      <td>1.619004e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2022-01-01T00:00:00Z</td>\n",
       "      <td>5.124345e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>source=maxar</td>\n",
       "      <td>2023-01-01T00:00:00Z</td>\n",
       "      <td>5.803140e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       state        source             timestamp         value\n",
       "0             Czech Republic     remainder  2018-01-01T00:00:00Z  2.690817e+08\n",
       "1             Czech Republic     remainder  2019-01-01T00:00:00Z  2.805054e+08\n",
       "2             Czech Republic     remainder  2020-01-01T00:00:00Z  2.919187e+08\n",
       "3             Czech Republic     remainder  2021-01-01T00:00:00Z  3.031043e+08\n",
       "4             Czech Republic     remainder  2022-01-01T00:00:00Z  3.100596e+08\n",
       "5             Czech Republic     remainder  2023-01-01T00:00:00Z  3.176620e+08\n",
       "6             Czech Republic  source=maxar  2018-01-01T00:00:00Z  0.000000e+00\n",
       "7             Czech Republic  source=maxar  2019-01-01T00:00:00Z  0.000000e+00\n",
       "8             Czech Republic  source=maxar  2020-01-01T00:00:00Z  1.433720e+03\n",
       "9             Czech Republic  source=maxar  2021-01-01T00:00:00Z  2.068170e+03\n",
       "10            Czech Republic  source=maxar  2022-01-01T00:00:00Z  1.003840e+04\n",
       "11            Czech Republic  source=maxar  2023-01-01T00:00:00Z  1.495826e+04\n",
       "12                   Germany     remainder  2018-01-01T00:00:00Z  2.079981e+09\n",
       "13                   Germany     remainder  2019-01-01T00:00:00Z  2.113747e+09\n",
       "14                   Germany     remainder  2020-01-01T00:00:00Z  2.144786e+09\n",
       "15                   Germany     remainder  2021-01-01T00:00:00Z  2.187509e+09\n",
       "16                   Germany     remainder  2022-01-01T00:00:00Z  2.224032e+09\n",
       "17                   Germany     remainder  2023-01-01T00:00:00Z  2.253637e+09\n",
       "18                   Germany  source=maxar  2018-01-01T00:00:00Z  0.000000e+00\n",
       "19                   Germany  source=maxar  2019-01-01T00:00:00Z  0.000000e+00\n",
       "20                   Germany  source=maxar  2020-01-01T00:00:00Z  3.597626e+05\n",
       "21                   Germany  source=maxar  2021-01-01T00:00:00Z  3.688894e+05\n",
       "22                   Germany  source=maxar  2022-01-01T00:00:00Z  3.302063e+05\n",
       "23                   Germany  source=maxar  2023-01-01T00:00:00Z  3.324734e+05\n",
       "24                   Vietnam     remainder  2018-01-01T00:00:00Z  1.486511e+08\n",
       "25                   Vietnam     remainder  2019-01-01T00:00:00Z  1.749341e+08\n",
       "26                   Vietnam     remainder  2020-01-01T00:00:00Z  2.070022e+08\n",
       "27                   Vietnam     remainder  2021-01-01T00:00:00Z  4.444431e+08\n",
       "28                   Vietnam     remainder  2022-01-01T00:00:00Z  5.253196e+08\n",
       "29                   Vietnam     remainder  2023-01-01T00:00:00Z  5.307533e+08\n",
       "30                   Vietnam  source=maxar  2018-01-01T00:00:00Z  0.000000e+00\n",
       "31                   Vietnam  source=maxar  2019-01-01T00:00:00Z  0.000000e+00\n",
       "32                   Vietnam  source=maxar  2020-01-01T00:00:00Z  2.309823e+04\n",
       "33                   Vietnam  source=maxar  2021-01-01T00:00:00Z  5.231692e+07\n",
       "34                   Vietnam  source=maxar  2022-01-01T00:00:00Z  1.133991e+08\n",
       "35                   Vietnam  source=maxar  2023-01-01T00:00:00Z  1.133421e+08\n",
       "36                   Nigeria     remainder  2018-01-01T00:00:00Z  5.281016e+08\n",
       "37                   Nigeria     remainder  2019-01-01T00:00:00Z  6.699778e+08\n",
       "38                   Nigeria     remainder  2020-01-01T00:00:00Z  6.893288e+08\n",
       "39                   Nigeria     remainder  2021-01-01T00:00:00Z  7.173629e+08\n",
       "40                   Nigeria     remainder  2022-01-01T00:00:00Z  7.514205e+08\n",
       "41                   Nigeria     remainder  2023-01-01T00:00:00Z  7.774466e+08\n",
       "42                   Nigeria  source=maxar  2018-01-01T00:00:00Z  0.000000e+00\n",
       "43                   Nigeria  source=maxar  2019-01-01T00:00:00Z  0.000000e+00\n",
       "44                   Nigeria  source=maxar  2020-01-01T00:00:00Z  1.519000e+01\n",
       "45                   Nigeria  source=maxar  2021-01-01T00:00:00Z  6.511065e+05\n",
       "46                   Nigeria  source=maxar  2022-01-01T00:00:00Z  4.281484e+06\n",
       "47                   Nigeria  source=maxar  2023-01-01T00:00:00Z  1.151075e+07\n",
       "48  United States of America     remainder  2018-01-01T00:00:00Z  1.065530e+10\n",
       "49  United States of America     remainder  2019-01-01T00:00:00Z  1.073248e+10\n",
       "50  United States of America     remainder  2020-01-01T00:00:00Z  1.081869e+10\n",
       "51  United States of America     remainder  2021-01-01T00:00:00Z  1.093930e+10\n",
       "52  United States of America     remainder  2022-01-01T00:00:00Z  1.106308e+10\n",
       "53  United States of America     remainder  2023-01-01T00:00:00Z  1.116729e+10\n",
       "54  United States of America  source=maxar  2018-01-01T00:00:00Z  0.000000e+00\n",
       "55  United States of America  source=maxar  2019-01-01T00:00:00Z  0.000000e+00\n",
       "56  United States of America  source=maxar  2020-01-01T00:00:00Z  7.345000e+01\n",
       "57  United States of America  source=maxar  2021-01-01T00:00:00Z  1.619004e+07\n",
       "58  United States of America  source=maxar  2022-01-01T00:00:00Z  5.124345e+07\n",
       "59  United States of America  source=maxar  2023-01-01T00:00:00Z  5.803140e+07"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_structure = transform_downloaded_data(json_data)\n",
    "df = pd.DataFrame(new_structure)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state    Czech Republic\n",
      "value               0.0\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state           Vietnam\n",
       "value    11167292955.27\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[[\"state\", \"value\"]].min())\n",
    "df[[\"state\", \"value\"]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
